{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't Use This\n",
    "\n",
    "This was an attempt at merging the input data. I later realized that this can be done far more efficiently later on with the PyTorch dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tiffs(data_dir):\n",
    "    os.makedirs(os.path.join(data_dir, \"images_merge\"), exist_ok=True)\n",
    "\n",
    "    tiff_files_li=[]\n",
    "    for ti in os.listdir(os.path.join(data_dir, \"images/\")):\n",
    "        if '.tif' in ti:\n",
    "            tiff_files_li.append(ti)\n",
    "        else:\n",
    "            shutil.copy(os.path.join(data_dir, \"images/\", ti), os.path.join(data_dir, \"images_merge/\", ti))\n",
    "    \n",
    "    for filename in tqdm(tiff_files_li):\n",
    "        infile1 = os.path.join(data_dir,\"images/\",filename)\n",
    "        infile2 = os.path.join(data_dir,\"images2/\",filename)\n",
    "        outfile = os.path.join(data_dir,\"images_merge/\",filename)\n",
    "        with rasterio.open(infile1) as dataset:\n",
    "            # read only the first three bands (omitting NIR)\n",
    "            data1 = dataset.read()[0:3,:,:]\n",
    "            crs1 = dataset.crs\n",
    "        with rasterio.open(infile2) as dataset:\n",
    "            data2 = dataset.read()\n",
    "            crs2 = dataset.crs\n",
    "        \n",
    "        # make sure image dimensions and crs are the same\n",
    "        assert data1.shape[-2:] == data2.shape[-2:]\n",
    "        assert crs1 == crs2\n",
    "\n",
    "        # convert dtypes for dem\n",
    "        # print(data2.dtype, np.min(data2), np.max(data2))\n",
    "        data2 = data2 - np.min(data2)\n",
    "        # print(data2.dtype, np.min(data2), np.max(data2))\n",
    "        data2 = data2 / (np.max(data2) / 255)\n",
    "        # print(data2.dtype, np.min(data2), np.max(data2))\n",
    "        data2 = data2.astype(data1.dtype)\n",
    "        # print(data2.dtype, np.min(data2), np.max(data2))\n",
    "\n",
    "        # print(data1.shape, data2.shape)\n",
    "        with rasterio.open(\n",
    "            outfile,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            count=data1.shape[0] + data2.shape[0],\n",
    "            height=data1.shape[1],\n",
    "            width=data1.shape[2],\n",
    "            dtype=data1.dtype,\n",
    "            crs=crs1,\n",
    "            compress='lzw',\n",
    "            PREDICTOR=2\n",
    "            ) as new_dataset:\n",
    "            # print(\"Output Shape:\", new_dataset.shape)\n",
    "            new_dataset.write(np.concatenate([data1, data2], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/Image_Chips_128_overlap_balanced_dem/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tiffs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = None\n",
    "for ti in os.listdir(os.path.join(data_dir, \"images/\")):\n",
    "        if '.tif' in ti:\n",
    "            testfile = ti\n",
    "            break\n",
    "testfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv.imread(os.path.join(data_dir, \"images/\", testfile))\n",
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = cv.imread(os.path.join(data_dir, \"images_merge/\", testfile))\n",
    "image3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.suptitle(\"Original Image (top) and Merged Image (bottom)\")\n",
    "bands1 = [\"B\", \"G\", \"R\", \"NIR\"]\n",
    "bands2 = [\"B\", \"G\", \"R\", \"DEM\"]\n",
    "# axs[0, 3].imshow(image1[:,:,3])\n",
    "# axs[1, 3].imshow(image3[:,:,3])\n",
    "# image1_noalpha = image1[:,:,:3]\n",
    "# image3_noalpha = image3[:,:,:3]\n",
    "for i in range(3):\n",
    "    axs[0, i].imshow(image1[:,:,i])\n",
    "    axs[0, i].set_title(bands1[i])\n",
    "    axs[0, i].set_axis_off()\n",
    "    axs[1, i].imshow(image3[:,:,i])\n",
    "    axs[1, i].set_title(bands2[i])\n",
    "    axs[1, i].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet-ortho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
